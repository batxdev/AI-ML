{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implement feature scaling and one hot encoding data preprocessing\n",
        "techniques on the dataset imported in lab 4 or any other dataset."
      ],
      "metadata": {
        "id": "RqcBQ5qPw5G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('student-dataset.csv')\n",
        "\n",
        "# Drop the column with all missing values\n",
        "data_cleaned = data.drop(columns=['ethnic.group'])\n",
        "\n",
        "# Feature Scaling: Standardizing the numeric columns\n",
        "scaler = StandardScaler()\n",
        "numeric_columns = ['english.grade', 'math.grade', 'sciences.grade',\n",
        "                   'language.grade', 'portfolio.rating',\n",
        "                   'coverletter.rating', 'refletter.rating']\n",
        "data_cleaned[numeric_columns] = scaler.fit_transform(data_cleaned[numeric_columns])\n",
        "\n",
        "# One-Hot Encoding: Encoding categorical columns ('gender', 'nationality', 'city')\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first')  # Using sparse_output=False for newer versions\n",
        "categorical_columns = ['gender', 'nationality', 'city']\n",
        "\n",
        "# Applying one-hot encoding and converting to a DataFrame\n",
        "encoded_data = pd.DataFrame(encoder.fit_transform(data_cleaned[categorical_columns]),\n",
        "                            columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "# Concatenate the encoded columns back to the scaled dataset and drop the original categorical columns\n",
        "data_preprocessed = pd.concat([data_cleaned.drop(columns=categorical_columns), encoded_data], axis=1)\n",
        "\n",
        "# Display the first few rows of the preprocessed dataset\n",
        "print(data_preprocessed.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4IW1NAjx1Dn",
        "outputId": "2d6fa96e-586c-4d5f-a6ee-ee0f80894a2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id             name  latitude  longitude  age  english.grade  math.grade  \\\n",
            "0   0        Kiana Lor     31.31     120.62   22       0.242250    0.600064   \n",
            "1   1   Joshua Lonaker     34.39    -118.54   22      -0.873312   -0.450219   \n",
            "2   2    Dakota Blanco     37.80    -122.27   22       0.985958    0.810121   \n",
            "3   3  Natasha Yarusso     37.69    -122.09   20      -0.129604   -1.290446   \n",
            "4   4   Brooke Cazares    -23.18     -45.88   21       0.614104   -1.710559   \n",
            "\n",
            "   sciences.grade  language.grade  portfolio.rating  ...  city_Vacaville  \\\n",
            "0       -0.681907       -3.413999          0.014052  ...             0.0   \n",
            "1        0.301859        0.606708          1.092527  ...             0.0   \n",
            "2       -0.485154        0.606708         -1.064423  ...             0.0   \n",
            "3       -0.485154        0.606708          1.092527  ...             0.0   \n",
            "4       -0.091647       -3.413999          0.014052  ...             0.0   \n",
            "\n",
            "   city_Vancouver  city_Visalia  city_Walnut Creek  city_Warsaw  \\\n",
            "0             0.0           0.0                0.0          0.0   \n",
            "1             0.0           0.0                0.0          0.0   \n",
            "2             0.0           0.0                0.0          0.0   \n",
            "3             0.0           0.0                0.0          0.0   \n",
            "4             0.0           0.0                0.0          0.0   \n",
            "\n",
            "   city_Waukegan  city_West Jordan  city_Wuhan  city_Zamora  city_ZÃ¼lpich  \n",
            "0            0.0               0.0         0.0          0.0           0.0  \n",
            "1            0.0               0.0         0.0          0.0           0.0  \n",
            "2            0.0               0.0         0.0          0.0           0.0  \n",
            "3            0.0               0.0         0.0          0.0           0.0  \n",
            "4            0.0               0.0         0.0          0.0           0.0  \n",
            "\n",
            "[5 rows x 204 columns]\n"
          ]
        }
      ]
    }
  ]
}